{
  "hash": "f44f51e9fa70dcf414eb5e7dc5097538",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Session 23 code\"\nauthor: \"Carolyn Koehn\"\nformat: html\n---\n\n\n\n\n# Code from last class\n\n## Pre-processing\n\n### Load libraries:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(terra)\nlibrary(tidyverse)\nlibrary(tmap)\nlibrary(tree)\nlibrary(randomForest)\n```\n:::\n\n\n\n\n### Load data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndownload_unzip_read <- function(link){\n  tmp <- tempfile()\n  download.file(link, tmp)\n  tmp2 <- tempfile()\n  unzip(zipfile=tmp, exdir=tmp2)\n  shapefile.sf <- read_sf(tmp2)\n}\n\n### FS Boundaries\nfs.url <- \"https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.AdministrativeForest.zip\"\nfs.bdry <- download_unzip_read(link = fs.url)\n\n### CFLRP Data\ncflrp.url <- \"https://data.fs.usda.gov/geodata/edw/edw_resources/shp/S_USA.CFLR_HPRP_ProjectBoundary.zip\"\ncflrp.bdry <- download_unzip_read(link = cflrp.url)\n\nwildfire_haz <- rast(\"/opt/data/data/assignment01/wildfire_hazard_agg.tif\")\n\ncejst <- st_read(\"/opt/data/data/assignment01/cejst_nw.shp\", quiet=TRUE) %>%\n  filter(!st_is_empty(.))\n```\n:::\n\n\n\n\n\n\n### Check validity:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall(st_is_valid(fs.bdry))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nall(st_is_valid(cflrp.bdry))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nfs.bdry <- st_make_valid(fs.bdry)\ncflrp.bdry <- st_make_valid(cflrp.bdry)\n```\n:::\n\n\n\n\n### Check alignment:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nst_crs(wildfire_haz) == st_crs(fs.bdry)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nst_crs(wildfire_haz) == st_crs(cflrp.bdry)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nst_crs(wildfire_haz) == st_crs(cejst)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nfs.bdry_proj <- st_transform(fs.bdry, crs = st_crs(wildfire_haz))\ncflrp.bdry_proj <- st_transform(cflrp.bdry, crs = st_crs(wildfire_haz))\ncejst_proj <- st_transform(cejst, crs = st_crs(wildfire_haz))\n```\n:::\n\n\n\n\n### Subset to relevant geographies:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfs.bdry_sub <- fs.bdry_proj[cejst_proj, ]\ncflrp.bdry_sub <- cflrp.bdry_proj[cejst_proj, ]\n\ncejst_sub <- cejst_proj[fs.bdry_sub, ]\n```\n:::\n\n\n\n\n### Select relevant attributes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncejst_sub <- cejst_sub %>%\n  select(GEOID10, LMI_PFS, LHE, HBF_PFS)\n```\n:::\n\n\n\n\n### Extract wildfire risk:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_risk <- terra::extract(wildfire_haz, cejst_sub, fun=mean)\n\ncejst_sub$WHP_ID <- wf_risk$WHP_ID\n```\n:::\n\n\n\n\n### CFLRP T or F:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncflrp <- apply(st_intersects(cejst_sub, cflrp.bdry_sub, sparse = FALSE), 1, any)\n\ncejst_sub$CFLRP <- cflrp\n```\n:::\n\n\n\n\n### Compare (three models)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncejst_mod <- cejst_sub %>%\n  st_drop_geometry(.) %>%\n  na.omit(.)\n\ncejst_mod[, c(\"LMI_PFS\", \"LHE\", \"HBF_PFS\", \"WHP_ID\")] <- scale(cejst_mod[, c(\"LMI_PFS\", \"LHE\", \"HBF_PFS\", \"WHP_ID\")])\n```\n:::\n\n\n\n\n#### Logistic regression:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic.global <- glm(CFLRP ~ LMI_PFS + LHE + HBF_PFS + WHP_ID,\n                       family = binomial(link = \"logit\"),\n                       data = cejst_mod)\nsummary(logistic.global)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = CFLRP ~ LMI_PFS + LHE + HBF_PFS + WHP_ID, family = binomial(link = \"logit\"), \n    data = cejst_mod)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.66462    0.14347  -4.632 3.62e-06 ***\nLMI_PFS      0.17284    0.16881   1.024    0.306    \nLHE         -0.25551    0.15791  -1.618    0.106    \nHBF_PFS     -0.01511    0.16081  -0.094    0.925    \nWHP_ID       0.88902    0.16785   5.297 1.18e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 330.74  on 255  degrees of freedom\nResidual deviance: 290.03  on 251  degrees of freedom\nAIC: 300.03\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\n\n\n\n#### Tree Model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tree)\ncejst_mod$CFLRP <- as.factor(ifelse(cejst_mod$CFLRP == 1, \"Yes\", \"No\"))\ntree.model <- tree(CFLRP ~ LMI_PFS + LHE + HBF_PFS + WHP_ID, cejst_mod)\n```\n:::\n\n\n\n\n#### Random Forest\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\nclass.model <- CFLRP ~ .\nrf2 <- randomForest(formula = class.model, cejst_mod[,-1])\n```\n:::\n\n\n\n\n# Model Comparison\n\n## Create train/test split\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# controls which random number generator is used so that my outputs will be consistent\n# use a different one than me and see how our results differ!\nset.seed(444)\n\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: lattice\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'caret'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n\n\n:::\n\n```{.r .cell-code}\n# get row numbers of training data split\n# cejst_mod$CFLRP is used to ensure ~equal yes/no split\nTrain <- createDataPartition(cejst_mod$CFLRP, p = 0.6, list=FALSE)\n\n# subset of our data corresponding to Train row numbers\ntraining <- cejst_mod[Train, ]\n# subset of our data NOT in the vector Train\ntesting <- cejst_mod[-Train, ]\n```\n:::\n\n\n\n\n## Confusion Matrices\n\n### Logistic regression\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# logistic regression fit with the training data\ntrain.log <- glm(CFLRP ~ LMI_PFS + LHE + HBF_PFS + WHP_ID,\n                       family = binomial(link = \"logit\"),\n                       data = training)\n\n# generate predictions for the testing data\nlog.pred <- predict(logistic.global, testing, type=\"response\")\n# assign predictions Yes/No based on probability\npred <- as.factor(ifelse(log.pred > 0.5, \n                         \"Yes\",\n                         \"No\"))\n# print confusion matrix and its metrics\nconfusionMatrix(testing$CFLRP, pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  61   5\n       Yes 26   9\n                                         \n               Accuracy : 0.6931         \n                 95% CI : (0.5934, 0.781)\n    No Information Rate : 0.8614         \n    P-Value [Acc > NIR] : 0.999996       \n                                         \n                  Kappa : 0.2111         \n                                         \n Mcnemar's Test P-Value : 0.000328       \n                                         \n            Sensitivity : 0.7011         \n            Specificity : 0.6429         \n         Pos Pred Value : 0.9242         \n         Neg Pred Value : 0.2571         \n             Prevalence : 0.8614         \n         Detection Rate : 0.6040         \n   Detection Prevalence : 0.6535         \n      Balanced Accuracy : 0.6720         \n                                         \n       'Positive' Class : No             \n                                         \n```\n\n\n:::\n:::\n\n\n\n\n### Tree Model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit tree model with training data\ntrain.tree <- tree(CFLRP ~ LMI_PFS + LHE + HBF_PFS + WHP_ID, training)\n# generate predictions for testing data\ntree.pred <- predict(train.tree, testing, type=\"class\")\n\nconfusionMatrix(testing$CFLRP, tree.pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  53  13\n       Yes 18  17\n                                         \n               Accuracy : 0.6931         \n                 95% CI : (0.5934, 0.781)\n    No Information Rate : 0.703          \n    P-Value [Acc > NIR] : 0.6329         \n                                         \n                  Kappa : 0.2988         \n                                         \n Mcnemar's Test P-Value : 0.4725         \n                                         \n            Sensitivity : 0.7465         \n            Specificity : 0.5667         \n         Pos Pred Value : 0.8030         \n         Neg Pred Value : 0.4857         \n             Prevalence : 0.7030         \n         Detection Rate : 0.5248         \n   Detection Prevalence : 0.6535         \n      Balanced Accuracy : 0.6566         \n                                         \n       'Positive' Class : No             \n                                         \n```\n\n\n:::\n:::\n\n\n\n\n### Random Forest\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit random forest with formula and training data\ntrain.rf <- randomForest(CFLRP ~ LMI_PFS + LHE + HBF_PFS + WHP_ID, training[,-1]) # leave out GEOID column\n# generate predictions for testing data\nrf.pred <- predict(train.rf, testing, type=\"response\")\n\nconfusionMatrix(testing$CFLRP, rf.pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction No Yes\n       No  49  17\n       Yes 17  18\n                                          \n               Accuracy : 0.6634          \n                 95% CI : (0.5625, 0.7544)\n    No Information Rate : 0.6535          \n    P-Value [Acc > NIR] : 0.4626          \n                                          \n                  Kappa : 0.2567          \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.7424          \n            Specificity : 0.5143          \n         Pos Pred Value : 0.7424          \n         Neg Pred Value : 0.5143          \n             Prevalence : 0.6535          \n         Detection Rate : 0.4851          \n   Detection Prevalence : 0.6535          \n      Balanced Accuracy : 0.6284          \n                                          \n       'Positive' Class : No              \n                                          \n```\n\n\n:::\n:::\n\n\n\n\nBased on accuracy, perhaps logistic regression or tree is best?\n\n## ROC / AUC\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\npredict.tree <- predict(train.tree, newdata=testing, type=\"vector\")[,2]\npredict.rf <- predict(train.rf, newdata=testing, type=\"prob\")[,2]\n\nplot(roc(testing$CFLRP, log.pred), print.auc=TRUE)\nplot(roc(testing$CFLRP, predict.tree), print.auc=TRUE, print.auc.y = 0.45, col=\"green\", add=TRUE)\nplot(roc(testing$CFLRP, predict.rf), print.auc=TRUE, print.auc.y = 0.4, col=\"blue\", add=TRUE)\n```\n\n::: {.cell-output-display}\n![](session-23-example_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\nBased on AUC, perhaps logistic regression or random forest is best?\n\n## Cross Validation\n\nNote that because we are folding our data, we're using `cejst_mod`, not `training` and `testing`!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set cross validation parameters\nfitControl <- trainControl(method = \"repeatedcv\", # fast resampling method but there are many\n                           number = 10,           # number of folds\n                           repeats = 10,          # number of complete sets of folds to compute\n                           classProbs = TRUE,     # compute probabilities, not just Yes/No\n                           summaryFunction = twoClassSummary)\n\n# run logistic regression with 10 folds across our entire dataset\nlog.model <- train(CFLRP ~., data = cejst_mod[,-1],\n                   # automatically uses family=binomial() for binary factor\n                   method = \"glm\",\n                   trControl = fitControl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in train.default(x, y, weights = w, ...): The metric \"Accuracy\" was not\nin the result set. ROC will be used instead.\n```\n\n\n:::\n\n```{.r .cell-code}\n# generate predictions for testing data\npred.log <- predict(log.model, newdata = testing, type=\"prob\")[,2]\n\n# run tree model with 10 folds across our entire dataset\ntree.model <- train(CFLRP ~., data = cejst_mod[,-1],\n                    method = \"rpart\",\n                    trControl = fitControl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in train.default(x, y, weights = w, ...): The metric \"Accuracy\" was not\nin the result set. ROC will be used instead.\n```\n\n\n:::\n\n```{.r .cell-code}\npred.tree <- predict(tree.model, newdata=testing, type=\"prob\")[,2]\n\n# random forest with 10 folds across our entire dataset\nrf.model <- train(CFLRP ~., data = cejst_mod[,-1],\n                  method = \"rf\",\n                  trControl = fitControl)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in train.default(x, y, weights = w, ...): The metric \"Accuracy\" was not\nin the result set. ROC will be used instead.\n```\n\n\n:::\n\n```{.r .cell-code}\npred.rf <- predict(rf.model, newdata=testing, type=\"prob\")[,2]\n\nplot(roc(testing$CFLRP, pred.log), print.auc=TRUE)\nplot(roc(testing$CFLRP, pred.tree), print.auc=TRUE, print.auc.y = 0.45, col=\"green\", add=TRUE)\nplot(roc(testing$CFLRP, pred.rf), print.auc=TRUE, print.auc.y = 0.4, col=\"blue\", add=TRUE)\n```\n\n::: {.cell-output-display}\n![](session-23-example_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n\nBased on cross validation (which is more robust than simple test/train splitting), random forest seems best.\n\n## Plotting the \"best\" model\n\nGet best models (highest AUC values came from cross-validation models):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest.rf <- rf.model$finalModel\nbest.log <- log.model$finalModel\nbest.tree <- tree.model$finalModel\n```\n:::\n\n\n\n\n\nWe can generate predictions for the vector data or convert to raster. I'll show both ways here for all models.\n\n### Predictions and Plotting for Vector Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlog.preds <- predict(object=best.log, newdata=cejst_mod, type=\"response\")\ntree.preds <- predict(object=best.tree, newdata=cejst_mod, type=\"class\")\nrf.preds <- predict(object=best.rf, newdata=cejst_mod, type=\"prob\")[,\"Yes\"]\n\n# get geometries back for plotting predictions\ncejst_pred <- left_join(cejst_mod, cejst_sub[,c(\"GEOID10\")]) %>%\n  st_as_sf(., crs = st_crs(cejst_sub)) %>%\n  # join predictions\n  mutate(logistic = log.preds,\n         # convert to numbers for plotting\n         tree = ifelse(tree.preds==\"Yes\", 1, 0),\n         rf = rf.preds)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(GEOID10)`\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# convert data to long format for mapping\nforest.cejst.long <- cejst_pred %>% \n  pivot_longer(., cols =logistic:rf, names_to=\"model\", values_to = \"pred\")\n\ntm_shape(forest.cejst.long) +\n  tm_fill(col=\"pred\") +\n  tm_facets(by = c(\"model\"), free.scales.fill = TRUE) +\n  tm_shape(cflrp.bdry_sub) +\n  tm_borders(col=\"black\", lwd=1.5)\n```\n\n::: {.cell-output-display}\n![](session-23-example_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\n### Predictions and Plotting for Raster Data\n\n**modified 11/12/24**\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# using wildfire raster as a template to rasterize all other predictors\npred.stack <- c((rasterize(cejst_sub, wildfire_haz, field = \"LMI_PFS\", \"mean\") - mean(cejst_sub$LMI_PFS, na.rm=TRUE))/sd(cejst_sub$LMI_PFS, na.rm=TRUE),\n                (rasterize(cejst_sub, wildfire_haz, field = \"LHE\", \"mean\") - mean(cejst_sub$LHE, na.rm=TRUE))/sd(cejst_sub$LHE, na.rm=TRUE),\n                (rasterize(cejst_sub, wildfire_haz, field = \"HBF_PFS\", \"mean\") - mean(cejst_sub$HBF_PFS, na.rm=TRUE))/sd(cejst_sub$HBF_PFS, na.rm=TRUE),\n                (wildfire_haz - mean(cejst_sub$WHP_ID, na.rm=TRUE))/sd(cejst_sub$WHP_ID, na.rm=TRUE))\nplot(pred.stack)\n```\n\n::: {.cell-output-display}\n![](session-23-example_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlog.preds_r <- terra::predict(pred.stack, best.log, type=\"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\ntree.preds_r <- terra::predict(pred.stack, best.tree, type=\"class\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\n# random forest doesn't like NAs, so we will replace them with 0 and then mask them out later\npred.stack_rf <- ifel(is.na(pred.stack), 0, pred.stack)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nrf.preds_r <- terra::predict(pred.stack_rf, best.rf, type=\"prob\")[[\"Yes\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\nresults <- c(log.preds_r, tree.preds_r, rf.preds_r)\nnames(results) <- c(\"Logistic\", \"Tree\", \"Random Forest\")\nresults <- mask(results, cejst_sub)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n```\n\n\n:::\n\n```{.r .cell-code}\npar(mfrow=c(1,3))\nplot(results[[1]], main=\"Logistic\")\nplot(st_geometry(cflrp.bdry_sub), add=TRUE)\nplot(results[[2]], main=\"Tree\")\nplot(st_geometry(cflrp.bdry_sub), add=TRUE)\nplot(results[[3]], main=\"Random Forest\")\nplot(st_geometry(cflrp.bdry_sub), add=TRUE)\n```\n\n::: {.cell-output-display}\n![](session-23-example_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "session-23-example_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}